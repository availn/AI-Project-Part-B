/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 
 *            COMP30024 Artificial Intelligence - Semester 1 2016            *
 *                  Project B - Playing a Game of Hexifence                  *
 *                                                                           *
 *                               Comments.txt                                *
 *                                                                           *
 *    Submission by: Julian Tran <juliant1> and Matt Farrugia <farrugiam>    *
 *                  Last Modified 16/05/16 by Matt Farrugia                  *
 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

Marks:

    4 - quality of code and comments (comments.txt? ask lida)
    4 - correctness and reliability (detecting and not making illegal moves)
    7 - results of testing
    7 - "creativity of solution"
	
Structure of Solution

    Packages and all that

Discussion of our Agent
	
	Our agent divides each game up into three parts - the opening, the midgame, and the endgame. After every move is made, the agent checks if it should change its strategy. This transition check is done based on the number of "safe" edges left, or, the number of edges left that can be placed without allowing a player to score. The agent switches from its opening strategy to its midgame strategy once there are less than 30 safe edges left, and from its midgame strategy to its endgame strategy once there are no safe edges left.
	
	Our opening strategy is to first make any move that increases our score. If there is no such move, then we make a random safe move. We are not using a minimax search at this point because we believe that there is limited benefit in doing so, as the search would have to be quite shallow due to the high branching factor, and we would have to construct a utility function. If we were to implement a search strategy here, then it would be Monte Carlo tree search (more detail here or at the bottom about how it works? cos I don't actually properly knwo how it works).
	
	Our midgame strategy is to first make any move that increases our score. If there is no such move, then we do a minimax search for the best safe move to make. Our search space is over all safe edges, as we could not find a situation where making an unsafe move would be beneficial, and are assuming that if such a situation exists, it would be rare enough to warrant trading a more complete search for a faster search. We consider any board state which has no safe edges to be a terminal state, and evaluate this state using a smaller minimax search on features (the chains, loops, and intersections that appear) followed by a heuristic playout. This evaluation determines which players will win or lose from this board state, with no gray area in between. This has the benefit of effectively implementing a fast alpha-beta pruning, because as soon as a player in the search expands a move which has a valuation where that player is expected to win, then that player can return that valuation immediately without expanding any further moves. This however relies on our evaluation function being correct, as an incorrect valuation can easily be returned all the way back up the search tree with this method.
	
	Our endgame strategy is to first make any move that both increases our score and does not create another move that can increase our score. This new condition stems from strategy seen in the more common "dots and boxes" game, where in the endgame, it is not optimal to greedily increase your score. Instead, optimal play involves "staying in control", where you force your opponent to open or "sacrifice" long chains of boxes, at which point you take all but two (or sometimes four) of the boxes, and "double box" the other two of the boxes, which forces the opponent, who is not in control, to take those few boxes, and sacrifice another long chain of boxes. Therefore, the only time we can be trivially sure that capturing a cell is a smart move, is when we know that capturing the cell does not make anotehr cell capturable.
	If there are no moves that allow for this, we can still maybe capture cells without thinking too much if we are not in a position to double box. So if we are still able to capture cells, we calculate how many cells we can capture before allowing the opponent to make their move. If this number is two, then we know we are in a position where we might want to double box, as if these two cells were capturable with the same move, then we would have made this move before doing this check. Likewise, if this number is four and one of the moves we would make in capturing these four cells would capture two cells at once, then we are also in a position where we might want to double box.
	Therefore, if we know we are in a position where we definitely do not want to double box, i.e. not in one of the aforementioned positions, then we can safely make moves that increase our score without needing to consider how the game will turn out. We only need to make sure that the edge we take does not remove the possibility that we are able to double box later on (Though the only time we should encounter this situation is when the opponent makes a very bad move).
	If we are in a position to double box, we need to determine whether it is actually a good idea to do so. We create a board state where it is as if we chose to double box (so the opponent has captured the cells we gave up and it is now their turn to move again), and then use our minimax search on features foloowed by a heuristic playout to play out the game from here, and check if we should be guaranteed the win. If so, then obviously double boxing is the right choice (though this results in our agent sometimes being quite disrespectful by double boxing as its very last move, effectively giving the opponent some score because our agent does not need it), and if not then we choose to just increase our own score.
	If there are no moves that increase our score, then we need to make a move that will allow the opponent to increase their score (making a sacrifice). Again, we use a minimax search on features followed by a heuristic playout to determine if we can be guaranteed a win from here. If so, then we make the sacrifice returned by the feature search, and if not we make the smallest sacrifice possible.
	
	- approach to opening (when to transition)
	- approach to midgame (approximate search)
	- approach to endgame (heuristic playouts)

Our Agent's Data Structures

    - Data Structures
        - EdgeSet making initial decisions take constant time to save on time
        - FeatureSet massively reduces branching factor by collecting equivalent moves towards the end of the game

Our Other Agents

    - AgentMe
    - AgentRandom
    - AgentGreedy
    - DoubleAgent

    which all really influenced the final design of AgentFarrugiulian

Other Creative Aspects: The Hexifence Visualisation Engine

    - Using LibGDX to render the board, also using a specialised Referee and specialised interfaces for Players and Boards so that I guess anyone could plug their solution into the visualiser
    
Other Creative Aspects: Possible Extensions and Research and stuff

    - Monte Carlo and Nims and stuff like that
    
    - Endgame Search more and stuff like that
    
    - Transposition table and Lexicographic Pruning (even though the latter of which turns out to be a dud!)

Fun times:

    Skype discussions and screenshots and paper and stuff (46 + 5 + 59 + 39 mins so far, plus 57 + 2:53, plus 1:28 + 1:27 + 11 + 3:34 + 46, plus 1:52 + 14 + ...)

    'after we finished talking about 4-loops, julian was struggling with for-loops'

    Independently both accidentally completing the midgame search function on the same morning.
